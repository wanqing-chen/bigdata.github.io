### 什么是状态

虽然数据流中的许多操作只是一次性查看一个单独的事件（例如事件解析器），但有些操作会记住多个事件之间的信息（例如窗口操作符）。这些操作被称为有状态操作。

一些有状态操作的例子：

- 当应用程序搜索特定事件模式时，状态将存储到目前为止遇到的事件序列。
- 当按分钟/小时/天聚合事件时，状态保存着待处理的聚合。
- 当在数据点流上训练机器学习模型时，状态保存着当前版本的模型参数。
- 当需要管理历史数据时，状态允许高效访问过去发生的事件。
- Flink 需要知道状态，以便使用检查点和保存点使其具有容错能力。

对状态的了解还允许对 Flink 应用程序进行**重新缩放**，这意味着 Flink 会负责在**并行实例之间重新分配状态**。

在处理状态时，了解 Flink 的状态后端也可能很有用。Flink 提供了不同的状态后端，这些后端指定了状态的存储方式和位置。

### Keyed State

键控状态维护在一个可以被认为是嵌入式键值存储的系统中。状态是**分区和分布**的，并且与读取状态的操作符的流严格一起。因此，只有在键控/分区数据交换之后，才能在**键控流上访问键值状态**，并且仅限于与当前事件的键相关联的值。流和状态的**键对齐**确保了所有状态更新都是**本地操作**，保证了**一致性**而没有**事务开销**。这种对齐还允许 Flink **透明地重新分配状态**并**调整流分区**。

键控状态进一步被组织成所谓的键组（Key Groups）。键组是 Flink 可以重新分配键控状态的原子单位；键组的数量恰好等于定义的最大并行度。在执行过程中，每个键控操作符的并行实例都与一个或多个键组的键一起工作。



### Key Groups 的作用：

- **状态管理**：每个 Key Group 包含一部分键控状态，Flink 可以对这些状态进行管理和维护。
- **并行处理**：Key Groups 使得 Flink 能够并行处理数据，每个并行任务处理一个或多个 Key Groups。
- **容错**：在发生故障时，Flink 可以恢复每个 Key Group 的状态，确保数据处理的一致性和准确性。
- **重新平衡**：当调整作业的并行度时，Flink 可以重新分配 Key Groups 到不同的任务，以实现状态的重新平衡。

### 简单例子：

假设我们正在处理一个电商网站的用户点击流数据，每个点击事件包含用户ID和点击的商品ID。我们想要计算每个用户的点击次数。

1. **数据流**：点击事件流，每个事件包含 `userId` 和 `productId`。
2. **键控流**：我们使用 `keyBy(userId)` 对数据流进行分区，这样相同 `userId` 的所有点击事件都会被分到同一个 Key Group。
3. **Key Groups**：假设我们设置的最大并行度是 4，Flink 会创建 4 个 Key Groups。每个 Key Group 包含一部分 `userId` 的点击事件。
4. **状态处理**：每个 Key Group 对应的并行任务会维护一个状态，用来计数该 Key Group 中每个 `userId` 的点击次数。
5. **调整并行度**：如果我们将并行度调整为 8，Flink 会自动将原来的 4 个 Key Groups 重新分配为 8 个，每个新任务处理更少的 Key Groups。

通过这个例子，我们可以看到 Key Groups 如何帮助 Flink 管理和重新分配键控状态，以及如何支持并行处理和动态调整并行度。这种机制使得 Flink 能够高效地处理大规模的数据流，同时保证状态的一致性和容错性。

### 状态持久化

Flink 通过**流重放**和**检查点（checkpointing）**的组合来实现容错。检查点标记了每个输入流中的一个特定点，以及每个操作符对应的状态。通过恢复操作符的状态并从检查点开始重放记录，可以在**保持一致性**（精确一次处理语义）的同时，从**检查点恢复流数据流**。

**检查点间隔**是一种在**执行期间容错的开销与恢复时间**（需要重放的记录数量）之间进行权衡的手段。

容错机制不断地对分布式流数据流进行快照。对于具有小状态的流应用程序，这些快照非常轻量级，可以频繁地进行，而对性能的影响很小。流应用程序的状态存储在可配置的位置，通常在**分布式文件系统**中。

如果程序发生故障（由于机器、网络或软件故障），Flink 会停止分布式流数据流。然后系统重新启动操作符并将它们**重置到最新的成功检查点**。输入流被**重置到状态快照的点**。作为重新启动的并行数据流的一部分而处理的任何记录都保证不会影响先前检查点的状态。

**默认情况下，检查点（checkpointing）是禁用的**。

为了使这种机制能够实现其完整的保证，数据流源（如消息队列或代理）需要能够将流回溯到一个定义的最近点。Apache Kafka 具有这种能力，Flink 的 Kafka 连接器利用了这一点。 

由于 Flink 的检查点是通过**分布式快照实现的**，我们交替使用快照（snapshot）和检查点（checkpoint）这两个词。通常，我们还使用术语快照来指代检查点或保存点（savepoint）。

### 检查点（Checkpointing）

Flink 容错机制的核心部分是**绘制分布式数据流**和**操作符状态的一致快照**。这些快照作为一致的检查点，系统在发生故障时可以回退到这些检查点。Flink 绘制这些快照的机制在“分布式数据流的轻量级异步快照”中有所描述。它受到分布式快照的标准**Chandy-Lamport** 算法的启发，并特别针对 Flink 的执行模型进行了定制。

请记住，与检查点相关的所有操作都可以**异步**完成。**检查点屏障不会同步移动**，操作可以**异步**地对它们的状态进行快照。

从 Flink 1.11 版本开始，检查点可以在有**对齐**或**无对齐**的情况下进行。在本节中，我们首先描述对齐的检查点。

### 屏障（Barriers）

Flink 分布式快照中的核心元素是**流屏障**。这些屏障被注入到数据流中，并作为数据流的一部分与记录一起流动。屏障永远不会**超过记录**，它们严格按**顺序流动**。屏障将数据流中的记录分为进入当前快照的记录集和进入下一个快照的记录集。每个屏障都带有它推动到其前面的快照的 ID。屏障不会中断流的流动，因此非常轻量级。来自不同快照的多个屏障可以同时在流中，这意味着可以同时**进行各种快照**。

流屏障被注入到流源的并行数据流中。注入快照 n 的屏障的位置（我们称之为 Sn）是源流中快照覆盖数据的截止位置。例如，在 Apache Kafka 中，这个位置将是分区中最后一个记录的偏移量。这个位置 **Sn 被报告给检查点协调器**（Flink 的 JobManager）。

然后，屏障向下流动。当一个**中间操作符**从其所有输入流接收到**快照 n **的屏障时，它会向其所有**输出流发射快照 n 的屏障**。一旦接收器操作符（流处理 DAG 的末端）从其所有输入流接收到屏障 n，它就会向**检查点协调器确认快照 n**。在所有接收器都确认了一个快照后，该快照就被认为是完成了。

一旦快照 n 完成，作业将不会再向源请求 Sn 之前的记录，因为到那时这些记录（及其后代记录）将已经通过了整个数据流拓扑。




<img src="article/flink/picture/屏障对齐机制.png" alt="图片alt" title="屏障对齐机制">
接收多个输入流的操作符需要在快照屏障上对输入流进行对齐。上面的图示说明了这一点：

一旦操作符从一个传入流接收到快照屏障 n，它就不能处理该流的任何进一步记录，直到它也从其他输入接收到屏障 n。否则，它会将属于快照 n 的记录与属于快照 n+1 的记录混合在一起。 
一旦最后一个流接收到屏障 n，操作符就会发出所有待处理的输出记录，然后自己发出快照 n 的屏障。 
它对状态进行快照，并从所有输入流恢复处理记录，先处理输入缓冲区中的记录，然后再处理来自流的记录。 
最后，操作符将状态异步写入状态后端。
**请注意，对齐对于所有具有多个输入的操作符以及在洗牌（shuffle）后消费多个上游子任务输出流的操作符都是必需的。**

### 操作符状态快照化

当操作符包含任何形式的状态时，这些状态也必须是快照的一部分。

操作符在从输入流接收到所有快照屏障时，并且在向输出流发出屏障之前，对其状态进行快照。在这一点上，来自屏障之前记录的所有状态更新都已完成，还没有应用任何依赖于屏障之后记录的更新。由于快照的状态可能很大，因此它被存储在可配置的状态后端中。默认情况下，这是**JobManager 的内存**，但对于生产环境，应该配置一个**分布式可靠存储**（如 HDFS）。在**状态被存储后**，**操作符确认检查点**，向输出流发出快照屏障，并继续进行。

生成的快照现在包含：

- 对于每个并行流数据源，在开始快照时流中的偏移量/位置
- 对于每个操作符，一个指向作为快照一部分存储的状态的指针
  <img src="article/flink/picture/检查点的整个生命周期.png" alt="图片alt" title="检查点的整个生命周期">

这张图片展示了 Flink 系统中检查点（Checkpoint）的整个生命周期，包括开始、进行中和完成三个阶段。图中使用了不同的时间点和位置来说明数据流和状态在检查点过程中的变化。以下是对每个阶段的详细解释：

### 1. 开始检查点（Starting Checkpoint）

- **Master 节点**：负责协调整个检查点过程。它发送开始检查点的消息，并记录检查点数据。
- **数据源（Source）**：在接收到开始检查点的消息后，数据源会发送特殊的流屏障（stream barriers）到下游操作符。这些屏障用于标记检查点的开始。
- **当前位置**：图中显示了三个不同的当前位置（5731, 7252, 5550），表示不同数据源或操作符在数据流中的位置。

### 2. 检查点进行中（Checkpoint in Progress）

- **操作符处理**：每个操作符在接收到所有输入流的屏障后，会对其状态进行快照，并发送确认（Ack）消息回 Master 节点，确认信息包括状态的偏移位置（如 6791）。
- **状态后端**：操作符的状态被异步写入配置的状态后端（如分布式文件系统）。
- **继续处理**：在状态快照完成后，操作符继续处理数据流中的记录。

### 3. 检查点进行中（Checkpoint in Progress）

- **发送下一个屏障**：操作符在确认当前检查点的状态后，会发送下一个检查点的屏障，为下一个检查点做准备。
- **状态指针**：图中显示了状态指针，这些指针指向存储在状态后端的状态数据。

### 4. 检查点完成（Checkpoint Completed）

- **确认完成**：所有操作符都确认了它们的检查点状态后，Master 节点认为检查点完成。
- **状态确认**：图中显示了状态后端中存储的检查点数据，包括每个数据源的状态和偏移位置。
- **接收所有屏障**：在接收到所有屏障后，操作符确认检查点完成，并继续处理新的数据记录。

这张图整体上展示了 Flink 如何通过流屏障和状态快照来实现检查点，以及如何确保在发生故障时能够从检查点恢复，从而保证数据处理的一致性和容错性。

### 恢复

在这种机制下，恢复是直接的：在发生故障时，Flink 会选择最新的已完成检查点 k。然后系统重新部署整个分布式数据流，并将检查点 k 中快照的状态提供给每个操作符。源被设置为从位置 Sk 开始读取流。例如，在 Apache Kafka 中，这意味着告诉消费者从偏移量 Sk 开始获取数据。

如果状态是以增量方式快照的，操作符将以最新的完整快照的状态开始，然后应用一系列增量快照更新到该状态。

### 非对齐检查点

检查点也可以以非对齐方式执行。基本思想是，只要在途数据成为操作符状态的一部分，检查点就可以超越所有在途数据。

请注意，这种方法实际上更接近 Chandy-Lamport 算法，但 Flink 仍然在源中插入屏障，以避免给检查点协调器带来过载。

<img src="article/flink/picture/非对齐检查点.png" alt="图片alt" title="非对齐检查点">
该图示描述了操作符如何处理非对齐检查点屏障：

- 操作符对其输入缓冲区中存储的第一个屏障做出反应。
- 它立即将屏障转发给下游操作符，将其添加到输出缓冲区的末尾。
- 操作符标记所有被超越的记录以便异步存储，并创建其自身状态的快照。
- 因此，操作符仅短暂停止处理输入以标记缓冲区、转发屏障，并创建其他状态的快照。

非对齐检查点确保屏障尽可能快地到达接收器。它特别适合至少有一个缓慢移动的数据路径的应用，其中对齐时间可能达到数小时。

然而，由于它增加了额外的 I/O 压力，所以当 I/O 到状态后端是瓶颈时，它并没有帮助。

请注意，保存点（savepoints）将始终是经过对齐的。



### 非对齐恢复

在非对齐检查点中，操作符首先恢复**在途数据**，然后才开始处理来自**上游操作符**的任何数据。除此之外，它执行的步骤与对齐检查点的恢复期间相同。

### 状态后端

键值索引存储的确切数据结构取决于所选择的状态后端。一种状态后端将**数据存储在内存中的哈希映射中**，另一种状态后端**使用 RocksDB 作为键值存储**。除了定义存储状态的数据结构外，状态后端还实现了逻辑以对**键值状态进行某一时刻的快照，并将该快照作为检查点的一部分进行存储**。**可以在不更改应用程序逻辑的情况下配置状态后端**。
<img src="article/flink/picture/状态后端触发.png" alt="图片alt" title="状态后端触发">

- **Job Manager** (master): **负责触发检查点（Trigger Checkpoint）**并**接收来自任务管理器（Task Manager）的确认检查点（Ack Checkpoint）消息**。
- **Task Manager** (workers):**多个任务管理器**，它们存储状态快照（store state snapshots）到快照存储（snapshot store）。

图片中显示了以下关系和流程：

- Job Manager 向 Task Managers 发送触发检查点的指令。
- Task Managers 在接收到触发检查点的指令后，存储它们的状态快照到配置的快照存储中。
- Task Managers 完成状态快照的存储后，向 Job Manager 发送确认检查点的指令。

### 保存点

所有使用检查点的程序都可以从保存点恢复执行。保存点允许更新您的程序和您的 Flink 集群，而不会丢失任何状态。

**保存点是手动触发的检查点**，它们对程序进行快照并将其写入到状态后端。它们依赖于常规的检查点机制来实现这一点。

保存点类似于检查点，除了它们是由用户触发的，并且在完成更新的检查点后不会自动过期。要正确使用保存点，了解检查点和保存点之间的区别非常重要，这在检查点与保存点的比较中有所描述。

### 精确一次（Exactly Once）与至少一次（At Least Once）

**对齐步骤可能会给流处理程序增加延迟。**通常，这种额外的延迟在几毫秒的范围内，但我们也见过一些异常情况，其中一些异常值的延迟明显增加。对于所有记录都要求始终保持极低延迟（几毫秒）的应用程序，Flink 提供了一个选项，可以在**检查点期间跳过流对齐**。即使在操作符从每个输入看到**检查点 n 的检查点屏障**后，检查点快照也会被绘制。

当跳过对齐时，即使某些检查点 n 的检查点屏障已经到达，操作符也会继续处理所有输入。这样，操作符在检查点 n 的状态快照被采取之前，也会处理属于检查点 n+1 的元素。在恢复时，这些记录将作为重复项出现，因为它们既包含在检查点 n 的状态快照中，也将作为检查点 n 之后的数据的一部分被重放。

这意味着，如果**跳过对齐，Flink 将提供至少一次的处理保证，即每个记录将至少被处理一次，但可能会有重复处理的情况**。这与精确一次的处理保证不同，后者确保每个记录在恢复时只被处理一次，但可能需要对齐步骤来实现，这可能会增加延迟。

**对齐（Alignment）仅在具有多个前驱（如连接操作）的操作符以及具有多个发送者（在流重新分区/混洗之后）的操作符中发生**。因此，仅包含并行流操作（如 map()、flatMap()、filter() 等）的数据流实际上即使在至少一次（At Least Once）模式下也能提供精确一次（Exactly Once）的处理保证。

### 批处理程序中的状态和容错性

Flink 在 BATCH 执行模式下将批处理程序作为流处理程序的特例执行，其中数据流是有界的（有限数量的元素）。因此，上述概念同样适用于批处理程序，与流处理程序类似，只是有轻微的例外：

批处理程序的容错性**不使用检查点机制**。恢复过程是通过完全重放数据流来实现的。这是可能的，因为输入是有界的。这将成本更多地推向了恢复过程，但使得常规处理更便宜，因为它避免了检查点。

在批处理执行模式下，状态后端使用简化的**内存/外核数据结构**，而不是键值索引。
